import torch
import torch.nn as nn
import pennylane as qml

# ============================================================
# å…¨åŸŸè¶…åƒæ•¸
# ============================================================
IMG_H = 8
IMG_W = 8

KERNEL_SIZE = 4
STRIDE = 2
N_KERNELS = 4           # é‡å­å·ç© kernel æ•¸é‡
N_POS_QUBITS = 4        # 4x4 patch â†’ 16 = 2**4 â†’ 4 qubits


# ============================================================
# å»ºç«‹é‡å­å·ç©ç”¨çš„ QNode
#   - input: amplitudes (len = 2**n_pos_qubits)
#   - weights: (n_pos_qubits, 3)
#   - output: (3,) = <X>, <Y>, <Z> on qubit 0
# ============================================================
def _make_qconv_qnode(n_pos_qubits: int):
    dev = qml.device("default.qubit", wires=n_pos_qubits)

    @qml.qnode(dev, interface="torch", diff_method="parameter-shift")
    def circuit(amps, weights):
        # amps: shape (2**n_pos_qubits,)
        # åœ¨å¤–éƒ¨æˆ‘å€‘å·²ç¶“åš L2 normalizeï¼Œé€™è£¡ normalize=False
        qml.AmplitudeEmbedding(amps, wires=range(n_pos_qubits), normalize=False)

        # ç°¡å–®çš„ä¸€å±¤åƒæ•¸åŒ–æ—‹è½‰ + entangling çµæ§‹
        for w in range(n_pos_qubits):
            qml.Rot(weights[w, 0], weights[w, 1], weights[w, 2], wires=w)

        # é€™è£¡å¯ä»¥åŠ ä¸€äº› entanglingï¼Œå¦‚æœæƒ³è¦æ›´è¤‡é›œï¼š
        for w in range(n_pos_qubits - 1):
            qml.CNOT(wires=[w, w + 1])
        qml.CNOT(wires=[n_pos_qubits - 1, 0])

        # åªé‡æ¸¬ qubit 0 çš„ X/Y/Z æœŸæœ›å€¼
        return (
            qml.expval(qml.PauliX(0)),
            qml.expval(qml.PauliY(0)),
            qml.expval(qml.PauliZ(0)),
        )

    return circuit


# ============================================================
# å–®ä¸€é‡å­ kernelï¼šå°ä¸€å€‹ patch ç”¢ç”Ÿ 3 ç¶­è¼¸å‡º
# ============================================================
class QKernel(nn.Module):
    """One quantum kernel: produces 3 output channels (X, Y, Z) per patch."""

    def __init__(self, n_pos_qubits: int):
        super().__init__()
        self.qnode = _make_qconv_qnode(n_pos_qubits)
        # trainable parameters: (n_pos_qubits, 3)
        self.weights = nn.Parameter(0.01 * torch.randn(n_pos_qubits, 3))

    def forward(self, patch_batch: torch.Tensor) -> torch.Tensor:
        """
        patch_batch: (B, 2**n_pos_qubits) L2-normalized amplitudes per sample
        returns: (B, 3)
        """
        outs = []
        for p in patch_batch:  # p: (2**n_pos_qubits,)
            q_out = self.qnode(p, self.weights)

            # qnode é€šå¸¸å›å‚³ list/tuple[scalar tensor]ï¼Œå…ˆè½‰æˆ 1D tensor
            if isinstance(q_out, (list, tuple)):
                q_out = torch.stack([torch.as_tensor(v) for v in q_out])
            else:
                q_out = torch.as_tensor(q_out)

            # ğŸ”’ NaN/Inf é˜²è­·
            q_out = torch.nan_to_num(q_out, nan=0.0, posinf=1.0, neginf=-1.0)

            outs.append(q_out)  # (3,)

        return torch.stack(outs, dim=0)  # (B, 3)


# ============================================================
# é‡å­ã€Œå·ç©å±¤ã€ï¼šæ¯å€‹ 4x4 patch â†’ amplitude encoding â†’ QKernel
# ============================================================
class QConv2d(nn.Module):
    """
    è¼¸å…¥: x (B, 1, H, W)
    æµç¨‹:
      - ä»¥ kernel_size/stride æ“·å– 4x4 patches
      - æ¯å€‹ patch flatten æˆé•·åº¦ 16 çš„å‘é‡
      - L2 normalize â†’ ç•¶ä½œ amplitude encoding
      - æ¯å€‹é‡å­ kernel QKernel ç”¢å‡º 3 ç¶­ç‰¹å¾µ (X, Y, Z)
    è¼¸å‡º: (B, 3 * n_kernels, H_out, W_out)
    """

    def __init__(self, kernel_size: int, stride: int, n_kernels: int, n_pos_qubits: int = N_POS_QUBITS):
        super().__init__()
        self.kernel_size = kernel_size
        self.stride = stride
        self.n_kernels = n_kernels
        self.n_pos_qubits = n_pos_qubits

        # å»ºç«‹å¤šå€‹é‡å­ kernel
        self.qkernels = nn.ModuleList(
            [QKernel(n_pos_qubits=self.n_pos_qubits) for _ in range(self.n_kernels)]
        )

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """
        x: (B, 1, H, W)
        return: (B, 3 * n_kernels, H_out, W_out)
        """
        assert x.dim() == 4, f"QConv2d expects 4D input (B,1,H,W), got {x.shape}"
        B, C, H, W = x.shape
        assert C == 1, f"QConv2d expects single channel input, got C={C}"

        # ä½¿ç”¨ unfold å–å¾—æ‰€æœ‰ 4x4 patches
        patches = (
            x.unfold(2, self.kernel_size, self.stride)   # dim=2 â†’ H
             .unfold(3, self.kernel_size, self.stride)   # dim=3 â†’ W
        )  # (B, 1, H_out, W_out, k, k)

        B, C, H_out, W_out, k, k2 = patches.shape
        assert k == self.kernel_size and k2 == self.kernel_size

        # æ”¤å¹³æˆ (B * H_out * W_out, k*k)
        patches = patches.contiguous().view(B * H_out * W_out, k * k)

        # L2 normalize â†’ amplitude vector
        eps = 1e-12
        norms = torch.linalg.vector_norm(patches, dim=-1, keepdims=True) + eps
        amps = patches / norms  # (B * H_out * W_out, k*k)
        amps = torch.nan_to_num(amps, nan=0.0, posinf=0.0, neginf=0.0)

        # é€šéæ¯å€‹é‡å­ kernel
        kernel_outputs = []
        for qk in self.qkernels:
            out_bl = qk(amps)  # (B*H_out*W_out, 3)
            out = out_bl.view(B, H_out, W_out, 3)  # (B, H_out, W_out, 3)
            kernel_outputs.append(out)

        # åœ¨æœ€å¾Œä¸€å€‹ç¶­åº¦ä¸²æ¥ kernels çš„è¼¸å‡º â†’ (B, H_out, W_out, 3 * n_kernels)
        feats = torch.cat(kernel_outputs, dim=-1)

        # è®Šæ›ç¶­åº¦ç‚º (B, 3*n_kernels, H_out, W_out)
        feats = feats.permute(0, 3, 1, 2).contiguous()

        # å†åšä¸€æ¬¡ NaN é˜²è­·
        feats = torch.nan_to_num(feats, nan=0.0, posinf=0.0, neginf=0.0)
        return feats


# ============================================================
# æ•´é«” QC-CNN åˆ†é¡æ¨¡å‹
#   - æ¥å— (B, 1, 8, 8) æˆ– (B, N>=64) flatten ç‰¹å¾µ
#   - å…ˆæ“·å–å‰ 64 ç¶­ reshape æˆ 8x8 ç°éš
#   - ç¶“éé‡å­å·ç© QConv2d
#   - flatten â†’ fc1(108â†’32) â†’ fc2(32â†’n_classes)
# ============================================================
class QCCNN(nn.Module):
    def __init__(self, n_classes: int = 3):
        """
        é è¨­ n_classes=3ï¼Œå°æ‡‰ fashion_012 / mnist_179_1200 é€™é¡ 0/1/2 ä¸‰é¡æƒ…å¢ƒã€‚
        ä¹‹å¾Œè‹¥ç”¨åˆ° 10 é¡ï¼Œå¯åœ¨å¤–é¢æŒ‡å®š QCCNN(n_classes=10)ã€‚
        """
        super().__init__()
        self.qconv = QConv2d(kernel_size=KERNEL_SIZE, stride=STRIDE, n_kernels=N_KERNELS)
        self.act = nn.LeakyReLU(0.1)

        # QConv è¼¸å‡º shape: (B, 3*N_KERNELS, H_out, W_out)
        # H_out = W_out = (8 - 4)/2 + 1 = 3
        conv_out_dim = 3 * N_KERNELS * 3 * 3  # = 12 * 3 * 3 = 108

        self.fc1 = nn.Linear(conv_out_dim, 32)
        self.fc2 = nn.Linear(32, n_classes)

    def _ensure_image(self, x: torch.Tensor) -> torch.Tensor:
        """
        å°‡è¼¸å…¥è½‰æˆ (B,1,8,8)ï¼š
          - è‹¥ x: (B, N) ä¸” N >= 64 â†’ å–å‰ 64 ç¶­ reshape æˆ 8x8
          - è‹¥ x: (B,1,8,8) â†’ ç›´æ¥ä½¿ç”¨
        """
        B = x.shape[0]

        if x.dim() == 2:
            # x: (B, N) â†’ è‡³å°‘è¦ 64 å€‹ç‰¹å¾µ
            if x.shape[1] < IMG_H * IMG_W:
                raise ValueError(
                    f"Expected at least {IMG_H*IMG_W} features to reshape into 8x8, "
                    f"got {x.shape[1]}"
                )
            x = x[:, : IMG_H * IMG_W]
            x = x.view(B, 1, IMG_H, IMG_W)
            return x

        if x.dim() == 4 and x.shape[1:] == (1, IMG_H, IMG_W):
            return x

        raise AssertionError(
            f"Expected input of shape (B,1,{IMG_H},{IMG_W}) or flat (B,>= {IMG_H*IMG_W}), "
            f"got {tuple(x.shape)}"
        )

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """
        x: (B, N) æˆ– (B,1,8,8)
        returns: logits (B, n_classes)
        """
        B = x.shape[0]

        # 1) ç¢ºä¿æ˜¯ (B,1,8,8)
        x = self._ensure_image(x)

        # 2) é‡å­å·ç©
        x = self.qconv(x)  # (B, 3*N_KERNELS, 3, 3)
        x = torch.nan_to_num(x, nan=0.0, posinf=0.0, neginf=0.0)

        # 3) flatten + MLP
        x = self.act(x)
        x = x.reshape(B, -1)  # (B, 108)

        # dtype å°é½Š fc1 æ¬Šé‡ï¼ˆé¿å… Double/Float è¡çªï¼‰
        x = x.to(dtype=self.fc1.weight.dtype)

        x = self.act(self.fc1(x))  # (B, 32)
        x = self.fc2(x)            # (B, n_classes)

        return x




